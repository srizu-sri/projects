import sys
import asyncio
import uvicorn
import time
import json
import math
import numpy as np
import os
from PyQt6 import QtWidgets, QtGui, QtCore
from fastapi import FastAPI, WebSocket
from threading import Thread
from PyQt6.QtCore import Qt, QUrl, QThread, pyqtSignal
from functools import partial
from PyQt6.QtWidgets import (QLabel, QLineEdit, QPushButton, QVBoxLayout, QHBoxLayout, 
                            QWidget, QGroupBox, QGridLayout, QMainWindow, QFrame, 
                            QScrollArea, QSizePolicy, QInputDialog, QMessageBox, QProgressBar, QSizePolicy)
from PyQt6.QtCore import Qt, QSize, pyqtSignal, QTimer, QThread
from PyQt6.QtGui import QFont, QIcon, QColor, QPalette, QPixmap, QDesktopServices, QGuiApplication
import cv2
import mediapipe as mp
from datetime import datetime
import pyttsx3
import threading
import queue


# ---------------------------
# ML Model
# ---------------------------

class PoseEstimator:
    def __init__(self):
        self.mp_pose = mp.solutions.pose
        self.mp_hands = mp.solutions.hands  # Add MediaPipe hands
        self.pose = self.mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5)
        self.hands = self.mp_hands.Hands(min_detection_confidence=0.5, min_tracking_confidence=0.5)  # Initialize hands
        self.trained_poses = []  # Loaded from file (omitted here for brevity)
        self.named_poses = {}  # Dictionary to store named poses
        
        # Load saved poses if available
        self.load_poses()
        
    def calculate_angle(self, a, b, c):
        a, b, c = np.array(a), np.array(b), np.array(c)
        ba, bc = a - b, c - b
        cosine_angle = np.dot(ba, bc) / (np.linalg.norm(ba) * np.linalg.norm(bc))
        return np.degrees(np.arccos(np.clip(cosine_angle, -1.0, 1.0)))

    def calculate_distance(self, a, b):
        """Calculate the Euclidean distance between two landmarks"""
        a, b = np.array(a), np.array(b)
        return np.linalg.norm(a - b)
        
    def extract_joint_angles(self, landmarks):
        keypoints = [(lm.x, lm.y) for lm in landmarks]
        angles = {
            "left_elbow": self.calculate_angle(keypoints[11], keypoints[13], keypoints[15]),
            "right_elbow": self.calculate_angle(keypoints[12], keypoints[14], keypoints[16]),
            "left_shoulder": self.calculate_angle(keypoints[13], keypoints[11], keypoints[23]),
            "right_shoulder": self.calculate_angle(keypoints[14], keypoints[12], keypoints[24]),
            "left_knee": self.calculate_angle(keypoints[23], keypoints[25], keypoints[27]),
            "right_knee": self.calculate_angle(keypoints[24], keypoints[26], keypoints[28])
        }
        
        # Add distances between key landmarks
        distances = {
            # Upper body distances
            "shoulder_width": self.calculate_distance(keypoints[11], keypoints[12]),
            "left_arm_length": self.calculate_distance(keypoints[11], keypoints[13]) + 
                              self.calculate_distance(keypoints[13], keypoints[15]),
            "right_arm_length": self.calculate_distance(keypoints[12], keypoints[14]) + 
                               self.calculate_distance(keypoints[14], keypoints[16]),
            
            # Lower body distances
            "hip_width": self.calculate_distance(keypoints[23], keypoints[24]),
            "left_leg_length": self.calculate_distance(keypoints[23], keypoints[25]) + 
                              self.calculate_distance(keypoints[25], keypoints[27]),
            "right_leg_length": self.calculate_distance(keypoints[24], keypoints[26]) + 
                               self.calculate_distance(keypoints[26], keypoints[28]),
            
            # Torso measurements
            "torso_length": self.calculate_distance(
                ((keypoints[11][0] + keypoints[12][0])/2, (keypoints[11][1] + keypoints[12][1])/2), 
                ((keypoints[23][0] + keypoints[24][0])/2, (keypoints[23][1] + keypoints[24][1])/2)
            )
        }
        
        # Combine angles and distances
        pose_features = {**angles, **distances}
        return pose_features
    
    def calculate_pose_accuracy(self, current_features, target_pose=None):
        """
        Calculate accuracy of current pose compared to a target pose.
        considering both angles and distances between landmarks.
        
        Returns:
        float: Accuracy percentage (0-100)
        """
        # If we have target poses to compare against
        if target_pose and target_pose in self.named_poses:
            target_features = self.named_poses[target_pose]
            
            if target_features:
                # Calculate the difference between current and target features
                angle_diffs = []
                distance_diffs = []
                
                for feature, current_value in current_features.items():
                    if feature in target_features:
                        if "left_" in feature or "right_" in feature or "_knee" in feature or "_elbow" in feature or "_shoulder" in feature:
                            # This is an angle - normalize difference
                            diff = abs(current_value - target_features[feature])
                            angle_diffs.append(min(diff, 360 - diff) / 180.0)  # Normalize to 0-1
                        else:
                            # This is a distance - normalize by the target value
                            if target_features[feature] > 0:  # Avoid division by zero
                                diff = abs(current_value - target_features[feature]) / target_features[feature]
                                distance_diffs.append(min(1.0, diff))  # Cap at 1.0 (100% difference)
                
                # Weight angles more heavily than distances (70% angles, 30% distances)
                if angle_diffs and distance_diffs:
                    avg_angle_diff = sum(angle_diffs) / len(angle_diffs)
                    avg_distance_diff = sum(distance_diffs) / len(distance_diffs)
                    weighted_diff = (0.7 * avg_angle_diff) + (0.3 * avg_distance_diff)
                    accuracy = max(0, 100 - (weighted_diff * 100))
                    return accuracy
                elif angle_diffs:
                    # Fall back to just angles if no distances
                    avg_diff = sum(angle_diffs) / len(angle_diffs)
                    accuracy = max(0, 100 - (avg_diff * 100))
                    return accuracy
        
        # If we don't have target poses or couldn't calculate accuracy based on features,
        # return a simulated accuracy based on detection quality
        # For demo purposes, we'll return a value between 50-95%
        return np.random.uniform(50, 95)
    
    def add_named_pose(self, name, features):
        """Add a named pose to the dictionary"""
        self.named_poses[name] = features
        # Save poses to file whenever a new one is added
        self.save_poses() 
               
    def save_poses(self):
        """Save all poses to a JSON file"""
        # Create poses directory if it doesn't exist
        os.makedirs("poses", exist_ok=True)
        
        # Convert numpy arrays to lists for JSON serialization
        serializable_poses = {}
        for name, features in self.named_poses.items():
            serializable_poses[name] = {k: float(v) for k, v in features.items()}
            
        # Save to file
        with open("poses/saved_poses.json", "w") as f:
            json.dump(serializable_poses, f)
            
    def load_poses(self):
        """Load poses from JSON file if it exists"""
        try:
            if os.path.exists("poses/saved_poses.json"):
                with open("poses/saved_poses.json", "r") as f:
                    loaded_poses = json.load(f)
                
                # Convert the loaded poses to the new format if they're in the old format
                self.named_poses = {}
                for name, features in loaded_poses.items():
                    # Check if this is an old format pose (only has angles)
                    if all(key in ["left_elbow", "right_elbow", "left_shoulder", 
                                  "right_shoulder", "left_knee", "right_knee"] 
                           for key in features.keys()):
                        print(f"Converting pose {name} to new format")
                        # This is an old format - we'll keep it as is for now
                        # The next time the user captures this pose, it will be updated
                        self.named_poses[name] = features
                    else:
                        # This is already in the new format
                        self.named_poses[name] = features
                
                print(f"Loaded {len(self.named_poses)} saved poses")
        except Exception as e:
            print(f"Error loading saved poses: {e}")
            # If there's an error, start with empty poses
            self.named_poses = {}

    def detect_open_palm(self, hand_landmarks):
        """Detects an open palm based on the position of all five fingertips."""
        if not hand_landmarks:
            return False
        fingertips = [hand_landmarks.landmark[i] for i in [4, 8, 12, 16, 20]]  # Thumb and four fingers
        wrist = hand_landmarks.landmark[0]
        open_fingers = [np.linalg.norm(np.array([tip.x, tip.y]) - np.array([wrist.x, wrist.y])) for tip in fingertips]
        return all(dist > 0.1 for dist in open_fingers)
    # Add this method to your PoseEstimator class
    def is_full_body_visible(self, landmarks):
        """
        Check if the full body is visible in the frame.
        Returns True if all key body landmarks are visible with sufficient confidence.
        """
        # Define key landmarks that must be visible for full body detection
        # These include ankles, knees, hips, shoulders, elbows, wrists
        key_landmarks = [
            11, 12,  # shoulders
            13, 14,  # elbows
            15, 16,  # wrists
            23, 24,  # hips
            25, 26,  # knees
        ]
        
        # Check if all key landmarks are visible with sufficient confidence
        # MediaPipe visibility score ranges from 0 to 1
        visibility_threshold = 0.65
        
        for idx in key_landmarks:
            if idx >= len(landmarks) or landmarks[idx].visibility < visibility_threshold:
                return False
        
        return True

class CalorieCalculator:
    def __init__(self):
        # MET values for different yoga intensities
        self.yoga_met_values = {
            "light": 2.5,       # Light/Hatha yoga
            "moderate": 3.5,    # Moderate/Vinyasa flow
            "intense": 4.5      # Power yoga/Ashtanga
        }
        
    def calculate_calories_from_heart_rate(self, heart_rate, weight_kg, age, gender, duration_minutes):
        """
        Calculate calories burned based on heart rate using the Keytel equation
        
        Parameters:
        - heart_rate: Average heart rate during exercise (BPM)
        - weight_kg: Weight in kilograms
        - age: Age in years
        - gender: 'male' or 'female'
        - duration_minutes: Exercise duration in minutes
        
        Returns:
        - Calories burned
        """
        if heart_rate < 40 or heart_rate > 220:
            return 0  # Invalid heart rate
            
        gender_factor = 1 if gender.lower() == 'male' else 0
        
        # Keytel equation (2005)
        calories = duration_minutes * ((0.2017 * age + 0.1988 * weight_kg + 0.6309 * heart_rate - 55.0969) * gender_factor + 
                                      (0.074 * age + 0.1263 * weight_kg + 0.4472 * heart_rate - 20.4022) * (1 - gender_factor)) / 4.184
        
        return max(0, calories)
    
    def calculate_calories_from_met(self, weight_kg, duration_hours, yoga_intensity="moderate", body_temp=37.0, bmi=22.0):
        """
        Calculate calories burned based on MET value, adjusted for body temperature and BMI
        
        Parameters:
        - weight_kg: Weight in kilograms
        - duration_hours: Exercise duration in hours
        - yoga_intensity: 'light', 'moderate', or 'intense'
        - body_temp: Body temperature in Celsius
        - bmi: Body Mass Index
        
        Returns:
        - Calories burned
        """
        # Get base MET value for the yoga intensity
        base_met = self.yoga_met_values.get(yoga_intensity.lower(), 3.0)
        
        # Adjust MET based on body temperature (higher temp = higher metabolism)
        # Normal body temp is ~37°C, each degree above increases metabolism by ~13%
        temp_adjustment = 1.0 + max(0, (body_temp - 37.0) * 0.13)
        
        # Adjust MET based on BMI (higher BMI = more effort for same activity)
        # Normal BMI is 18.5-24.9, we'll use 22 as baseline
        if bmi < 18.5:
            bmi_adjustment = 0.95  # Underweight: slightly less calories burned
        elif bmi < 25:
            bmi_adjustment = 1.0   # Normal weight
        elif bmi < 30:
            bmi_adjustment = 1.05  # Overweight: slightly more calories burned
        else:
            bmi_adjustment = 1.1   # Obese: more calories burned
            
        # Calculate adjusted MET
        adjusted_met = base_met * temp_adjustment * bmi_adjustment
        
        # Calculate calories: MET × weight (kg) × duration (hours)
        calories = adjusted_met * weight_kg * duration_hours
        
        return calories
    
    def get_yoga_intensity(self, pose_name):
        """
        Determine the intensity level of a yoga pose
        
        Parameters:
        - pose_name: Name of the yoga pose
        
        Returns:
        - Intensity level: 'light', 'moderate', or 'intense'
        """
        # Dictionary of common yoga poses and their intensities
        pose_intensities = {
            # Light intensity poses
            "mountain pose": "light",
            "child's pose": "light",
            "corpse pose": "light",
            "easy pose": "light",
            "seated forward bend": "light",
            
            # Moderate intensity poses
            "downward dog": "moderate",
            "warrior i": "moderate",
            "warrior ii": "moderate",
            "triangle pose": "moderate",
            "tree pose": "moderate",
            
            # High intensity poses
            "crow pose": "intense",
            "handstand": "intense",
            "headstand": "intense",
            "wheel pose": "intense",
            "side plank": "intense"
        }
        
        # Check if the pose is in our dictionary
        pose_lower = pose_name.lower()
        for pose_key, intensity in pose_intensities.items():
            if pose_key in pose_lower:
                return intensity
                
        # Default to moderate if pose not found
        return "moderate"

# ---------------------------
# FastAPI WebSocket Server
# ---------------------------
app = FastAPI()
# Initialize with default values for all ESP32 devices
esp_data = {
    # Health metrics from ESP32 with MAX30102 and MPU6050
    "heart_rate": 0, 
    "spo2": 0, 
    "body_temp_pre": 0,  # From MAX30102 temperature sensor (SDA,SCL=18,19)
    "body_temp_post": 0, # From MLX90614 temperature sensor (SDA,SCL=21,22)
    
    # Exercise metrics from MPU6050 (SDA,SCL=18,19)
    "steps": 0,
    "strength_count": 0,
    
    # Camera status from ESP32S3
    "camera_status": "disconnected"
}

# Create separate WebSocket endpoints for each ESP32
@app.websocket("/esp32/health")
async def health_websocket(websocket: WebSocket):
    await websocket.accept()
    while True:
        try:
            data = await websocket.receive_text()
            print(f"Received health data: {data}")  # Debug print
            parsed = json.loads(data)
            
            # Update health-related metrics from MAX30102 (SDA,SCL=18,19) and MLX90614 (SDA,SCL=21,22)
            for key in ["heart_rate", "spo2", "body_temp_pre", "body_temp_post"]:
                if key in parsed:
                    # For heart_rate, ensure we're getting a valid number
                    if key == "heart_rate" and (parsed[key] is None or parsed[key] == 0):
                        # If IR value is present and high enough, calculate heart rate
                        if "ir_value" in parsed and parsed["ir_value"] > 50000:
                            # Use a default heart rate range based on IR value
                            # This is a fallback when the sensor's algorithm fails
                            esp_data[key] = max(60, min(100, int(parsed["ir_value"] / 1500)))
                        else:
                            esp_data[key] = 0
                    else:
                        esp_data[key] = parsed[key]
            
            # Explicitly handle MPU6050 data (steps and strength_count)
            if "steps" in parsed:
                esp_data["steps"] = parsed["steps"]
                print(f"Updated steps: {esp_data['steps']}")
            
            if "strength_count" in parsed:
                esp_data["strength_count"] = parsed["strength_count"]
                print(f"Updated strength count: {esp_data['strength_count']}")
            
            # Update sensor status
            if "max30102_status" in parsed:
                esp_data["max30102_status"] = parsed["max30102_status"]
            
            if "mpu6050_status" in parsed:
                esp_data["mpu6050_status"] = parsed["mpu6050_status"]
            
            if "mlx90614_status" in parsed:
                esp_data["mlx90614_status"] = parsed["mlx90614_status"]
            
            # Print updated values for debugging
            print(f"Updated health data: {esp_data}")
        except Exception as e:
            print(f"Error in health websocket: {e}")
            await asyncio.sleep(1)
@app.websocket("/esp32/exercise")
async def exercise_websocket(websocket: WebSocket):
    await websocket.accept()
    while True:
        try:
            data = await websocket.receive_text()
            print(f"Received exercise data: {data}")  # Debug print
            parsed = json.loads(data)
            # Update only exercise-related metrics
            for key in ["steps", "strength_count"]:
                if key in parsed:
                    esp_data[key] = parsed[key]
            print(f"Updated exercise data: {esp_data}")  # Debug print
        except Exception as e:
            print(f"Error in exercise websocket: {e}")
            await asyncio.sleep(1)

@app.websocket("/esp32/camera")
async def camera_websocket(websocket: WebSocket):
    await websocket.accept()
    while True:
        try:
            data = await websocket.receive_text()
            parsed = json.loads(data)
            # Update camera status
            if "camera_status" in parsed:
                esp_data["camera_status"] = parsed["camera_status"]
        except Exception as e:
            print(f"Error in camera websocket: {e}")
            await asyncio.sleep(1)

# Original endpoint for backward compatibility
@app.websocket("/esp32")
async def websocket_endpoint(websocket: WebSocket):
    await websocket.accept()
    while True:
        try:
            data = await websocket.receive_text()
            parsed = json.loads(data)
            esp_data.update(parsed)
        except Exception as e:
            print(f"Error in general websocket: {e}")
            await asyncio.sleep(1)

# Add route for ESP32-CAM stream
@app.get("/")
async def get_index():
    return {"message": "YogKalp API is running"}

# Run FastAPI in thread
def run_fastapi():
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)

# Start the FastAPI server in a separate thread
Thread(target=run_fastapi, daemon=True).start()

# ---------------------------
# ESP32 Camera Stream Receiver
# ---------------------------

class SplashScreen(QWidget):
    def __init__(self):
        super().__init__()
        self.setWindowTitle("YogKalp")
        self.setFixedSize(500, 400)
        self.setWindowFlag(Qt.WindowType.FramelessWindowHint)
        self.setAttribute(Qt.WidgetAttribute.WA_TranslucentBackground)
        
        # Center the splash screen
        self.center()
        
        # Set up the layout
        layout = QVBoxLayout()
        layout.setContentsMargins(10, 10, 10, 10)
        
        # Create a frame to hold the content
        container = QFrame()
        container.setObjectName("splash_container")
        container.setStyleSheet("""
            #splash_container {
                background-color: #FFFFFF;
                border-radius: 20px;
            }
        """)
        
        # Layout for the container
        container_layout = QVBoxLayout(container)
        container_layout.setAlignment(Qt.AlignmentFlag.AlignCenter)
        
        # Add logo
        logo_label = QLabel()
        logo_pixmap = QPixmap("c:/Users/sriva/OneDrive/Desktop/YogKalp/YogKalp_logo.jpg")
        logo_label.setPixmap(logo_pixmap.scaled(400, 150, Qt.AspectRatioMode.KeepAspectRatio, Qt.TransformationMode.SmoothTransformation))
        logo_label.setAlignment(Qt.AlignmentFlag.AlignCenter)
        container_layout.addWidget(logo_label)
        
        # Add loading text
        loading_label = QLabel("Loading...")
        loading_label.setAlignment(Qt.AlignmentFlag.AlignCenter)
        loading_label.setFont(QFont("Google Sans", 12))
        container_layout.addWidget(loading_label)
        
        # Add progress bar
        self.progress = QProgressBar()
        self.progress.setRange(0, 100)
        self.progress.setValue(0)
        self.progress.setTextVisible(False)
        self.progress.setStyleSheet("""
            QProgressBar {
                border: none;
                background-color: #F0F0F0;
                border-radius: 10px;
                height: 10px;
            }
            QProgressBar::chunk {
                background-color: #FF9800;
                border-radius: 10px;
            }
        """)
        container_layout.addWidget(self.progress)
        
        # Add the container to the main layout
        layout.addWidget(container)
        self.setLayout(layout)
        
        # Timer for progress
        self.timer = QtCore.QTimer()
        self.timer.timeout.connect(self.update_progress)
        self.timer.start(30)
        
        self.counter = 0
        
    def update_progress(self):
        self.counter += 1
        self.progress.setValue(self.counter)
        
        if self.counter >= 100:
            self.timer.stop()
            self.close()
            self.main_app = ModernYogaApp()
            self.main_app.show()
    
    def center(self):
        """Center the window on the screen"""
        # Fix: Use QtWidgets.QApplication instead of QApplication
        screen_geometry = QtWidgets.QApplication.primaryScreen().geometry()
        x = (screen_geometry.width() - self.width()) // 2
        y = (screen_geometry.height() - self.height()) // 2
        self.move(x, y)

class ESP32CameraReceiver:
    def __init__(self, url=None):
        self.url = url if url else "http://192.168.64.89/stream"  # ESP32-CAM IP
        self.cap = None
        self.connected = False
        self.reconnect_attempts = 0
        self.max_reconnect_attempts = 5
        self.connection_timeout = 3  # Timeout in seconds for connection attempts
        
    def connect(self):
        try:
            print(f"Connecting to ESP32-CAM at {self.url}")
            
            # Set a timeout for the connection attempt
            os.environ['OPENCV_FFMPEG_READ_ATTEMPTS'] = '1'  # Limit read attempts
            os.environ['OPENCV_FFMPEG_CAPTURE_OPTIONS'] = 'timeout;3000|rtsp_transport;tcp'
            
            # Try to open the camera with a timeout
            self.cap = cv2.VideoCapture(self.url, cv2.CAP_FFMPEG)
            
            # Check if connection was successful
            start_time = time.time()
            while time.time() - start_time < self.connection_timeout:
                self.connected = self.cap.isOpened()
                if self.connected:
                    # Try to read a frame to confirm connection
                    ret, _ = self.cap.read()
                    if ret:
                        self.reconnect_attempts = 0
                        print("Successfully connected to ESP32-CAM")
                        return True
                time.sleep(0.5)
            
            # If we get here, connection failed
            print("Failed to connect to ESP32-CAM - timeout")
            if self.cap:
                self.cap.release()
                self.cap = None
            self.connected = False
            self.reconnect_attempts += 1
            return False
            
        except Exception as e:
            print(f"Error connecting to ESP32-CAM: {e}")
            if self.cap:
                self.cap.release()
                self.cap = None
            self.connected = False
            self.reconnect_attempts += 1
            return False
            
    def read_frame(self):
        if not self.connected or not self.cap:
            if self.reconnect_attempts < self.max_reconnect_attempts:
                print(f"Attempting to reconnect to ESP32-CAM (attempt {self.reconnect_attempts+1}/{self.max_reconnect_attempts})")
                self.connect()
            return False, None
            
        try:
            ret, frame = self.cap.read()
            if not ret:
                print("Failed to read frame from ESP32-CAM")
                self.connected = False
                return False, None
            return ret, frame
        except Exception as e:
            print(f"Error reading frame from ESP32-CAM: {e}")
            self.connected = False
            return False, None
            
    def release(self):
        if self.cap:
            try:
                self.cap.release()
            except Exception as e:
                print(f"Error releasing ESP32-CAM connection: {e}")
        self.connected = False
        self.reconnect_attempts = 0
        if self.cap:
            try:
                self.cap.release()
            except Exception as e:
                print(f"Error releasing ESP32-CAM connection: {e}")
        self.connected = False
        self.reconnect_attempts = 0
        
class CameraThread(QThread):
    # Define signals for thread-safe communication
    training_count_updated = pyqtSignal(int)
    accuracy_updated = pyqtSignal(float, str)
    model_updated = pyqtSignal()
    pose_count_updated = pyqtSignal(int)  # New signal for pose count
    camera_error = pyqtSignal(str)
    def __init__(self, pose_estimator):
        super().__init__()
        self.estimator = pose_estimator
        self.running = False
        self.training_images_count = 0
        # Initialize poses_trained based on loaded poses
        self.poses_trained = len(self.estimator.named_poses)
        self.current_pose_name = ""
        self.current_batch = []  # Current batch of pose angles
        self.palm_detected_time = None
        self.image_captured = False
        self.timer_active = False  # Flag to track if timer is active
        self.palm_detection_enabled = True  # Flag to enable/disable palm detection
        self.use_esp32_cam = False  # Flag to use ESP32-CAM instead of local camera
        self.esp32_cam = ESP32CameraReceiver()
        # Counters for voice feedback
        self.low_accuracy_feedback_count = 0
        self.medium_accuracy_feedback_count = 0
        self.last_accuracy_level = "high"  # Track the last accuracy level
        
    def set_pose_name(self, name):
        self.current_pose_name = name
        
    def save_current_batch(self, name):
        """Average the angles in the current batch and save as a named pose"""
        if self.current_batch:
            # Calculate average angles for each joint
            avg_angles = {}
            for key in self.current_batch[0].keys():
                avg_angles[key] = sum(batch[key] for batch in self.current_batch) / len(self.current_batch)
            
            # Save to estimator
            self.estimator.add_named_pose(name, avg_angles)
            # Reset batch
            self.current_batch = []
            
            # Update poses trained count
            self.poses_trained += 1
            self.pose_count_updated.emit(self.poses_trained)
            
            # Emit signal that model was updated
            self.model_updated.emit()
        
    def set_palm_detection_enabled(self, enabled):
        """Enable or disable palm detection feature"""
        self.palm_detection_enabled = enabled
    
    def set_esp32_cam_enabled(self, enabled, url=None):
        
        """Enable or disable ESP32-CAM stream"""
        self.use_esp32_cam = enabled
        if url:
            self.esp32_cam.url = url       
            
    def run(self):
        self.running = True
        
        # Create training images directory if it doesn't exist
        training_dir = "training_images"
        os.makedirs(training_dir, exist_ok=True)
        
        # Initialize camera source
        cap = None
        
        # Create modern-looking window
        cv2.namedWindow("Yoga Pose Analysis", cv2.WINDOW_NORMAL)
        cv2.resizeWindow("Yoga Pose Analysis", 640, 480)
        
        while self.running:
            # Try to initialize or check camera if not already done
            if self.use_esp32_cam and (not hasattr(self, 'esp32_cam_initialized') or not self.esp32_cam_initialized):
                # Try to connect to ESP32-CAM
                print("Attempting to connect to YogKalp-CAM...")
                if not self.esp32_cam.connect():
                    print("Failed to connect to YogKalp-CAM, falling back to local camera")
                    # Emit signal for camera error
                    self.camera_error.emit("YogKalp-CAM not available. Falling back to local camera.")
                    
                    # Try to use local camera instead
                    if cap is None or not cap.isOpened():
                        cap = cv2.VideoCapture(0)
                        if not cap.isOpened():
                            self.camera_error.emit("Local camera also not available. Please check your camera connections.")
                            time.sleep(2)  # Wait before retrying
                            continue
                    self.use_esp32_cam = False
                else:
                    print(f"Connected to YogKalp-CAM at {self.esp32_cam.url}")
                    self.esp32_cam_initialized = True
            elif not self.use_esp32_cam and (cap is None or not cap.isOpened()):
                # Initialize local camera if not already done
                cap = cv2.VideoCapture(0)
                if not cap.isOpened():
                    self.camera_error.emit("Local camera not available. Please check your camera connection.")
                    time.sleep(2)  # Wait before retrying
                    continue
            
            # Get frame from appropriate source
            if self.use_esp32_cam:
                ret, frame = self.esp32_cam.read_frame()
                if not ret:
                    print("Failed to get frame from YogKalp-CAM")
                    # Reset connection flag to force reconnection attempt
                    self.esp32_cam_initialized = False
                    time.sleep(1)
                    continue
            else:
                ret, frame = cap.read()
                if not ret:
                    print("Failed to get frame from local camera")
                    # Reset cap to force reconnection
                    if cap is not None:
                        cap.release()
                    cap = None
                    time.sleep(1)
                    continue
            
            # Process image for pose detection
            image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            results_pose = self.estimator.pose.process(image)
            
            # Process image for hand detection (for gesture control)
            results_hands = self.estimator.hands.process(image)
            
            image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)
            
            # Add fancy header
            cv2.rectangle(image, (0, 0), (image.shape[1], 60), (26, 115, 232), -1)
            cv2.putText(image, "Yoga Pose Analysis", (20, 40), 
                         cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)
                        
            # Add camera source indicator
            source_text = "ESP32-CAM" if self.use_esp32_cam else "Local Camera"
            cv2.putText(image, f"Source: {source_text}", (image.shape[1]-250, 80), 
                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (26, 115, 232), 2)
            
            # Add training images count
            cv2.putText(image, f"Training Images: {self.training_images_count}", 
                        (image.shape[1] - 250, 40), 
                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
            
            # Add instructions for training image capture
            instruction_text = "Press 'T' to capture training image"
            if self.palm_detection_enabled:
                instruction_text += " or show open palm to start 5s timer"
            
            cv2.putText(image, instruction_text, 
                        (20, image.shape[0] - 20), 
                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (26, 115, 232), 2)
            
            # Check for open palm gesture - only if timer is not already active AND palm detection is enabled
            if not self.timer_active and self.palm_detection_enabled and results_hands and results_hands.multi_hand_landmarks:
                for hand_landmarks in results_hands.multi_hand_landmarks:
                    if self.estimator.detect_open_palm(hand_landmarks):
                        # Start the timer but don't save the frame yet
                        self.palm_detected_time = time.time()
                        self.image_captured = False
                        self.timer_active = True  # Set timer as active
                        break
            
            # If timer is active, show countdown regardless of hand presence
            if self.timer_active and self.palm_detected_time is not None:
                elapsed = time.time() - self.palm_detected_time
                if elapsed < 5:
                    # Draw a countdown timer on screen
                    cv2.putText(image, f"Capturing in: {5-int(elapsed)}s", 
                                (image.shape[1]//2 - 100, image.shape[0]//2), 
                                cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)
                else:
                    # Timer completed, capture the CURRENT frame instead of the initial one
                    if not self.image_captured and results_pose.pose_landmarks:
                        # Save the current frame instead of the initial one
                        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                        filename = f"{training_dir}/training_pose_{timestamp}.jpg"
                        cv2.imwrite(filename, frame)  # Using current frame
                        self.training_images_count += 1
                        
                        # Extract angles and add to batch
                        angles = self.estimator.extract_joint_angles(results_pose.pose_landmarks.landmark)
                        self.current_batch.append(angles)
                        
                        # Emit signal that training count was updated
                        self.training_count_updated.emit(self.training_images_count)
                        
                        # Show feedback that image was saved
                        save_feedback = frame.copy()  # Using current frame for feedback
                        cv2.putText(save_feedback, "Image Saved!", (frame.shape[1]//2 - 100, frame.shape[0]//2), 
                                   cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0, 255, 0), 3)
                        cv2.imshow("Yoga Pose Analysis", save_feedback)
                        cv2.waitKey(500)  # Show feedback for half a second
                        
                        self.image_captured = True
                    
                    # Reset timer state
                    self.palm_detected_time = None
                    self.timer_active = False  # Reset timer active flag
            
            # In the CameraThread's run method, update the pose detection logic
            # Find the section where it processes pose landmarks and emits accuracy

            # Draw pose landmarks with custom style
            if results_pose.pose_landmarks:
                mp_drawing = mp.solutions.drawing_utils
                mp_drawing_styles = mp.solutions.drawing_styles
                
                # Extract joint angles
                angles = self.estimator.extract_joint_angles(results_pose.pose_landmarks.landmark)
                
                # Check if full body is visible before calculating accuracy
                full_body_visible = self.estimator.is_full_body_visible(results_pose.pose_landmarks.landmark)
                
                # Find the best matching pose from all trained poses
                best_pose = None
                best_accuracy = 0
                
                # Only proceed with pose matching if full body is visible
                if full_body_visible:
                    for pose_name, pose_angles in self.estimator.named_poses.items():
                        # Calculate accuracy for this pose
                        accuracy = self.estimator.calculate_pose_accuracy(angles, pose_name)
                        
                        # If this is the best match so far, update
                        if accuracy > best_accuracy:
                            best_accuracy = accuracy
                            best_pose = pose_name
                    
                    # If we found a good match, emit the signal with the best pose
                    if best_pose and best_accuracy > 40:  # Threshold to avoid false positives
                        self.accuracy_updated.emit(best_accuracy, best_pose)
                
                # Draw skeleton in Google blue color
                mp_drawing.draw_landmarks(
                    image, 
                    results_pose.pose_landmarks, 
                    self.estimator.mp_pose.POSE_CONNECTIONS,
                    landmark_drawing_spec=mp_drawing.DrawingSpec(color=(232, 115, 26), thickness=2, circle_radius=2),
                    connection_drawing_spec=mp_drawing.DrawingSpec(color=(26, 115, 232), thickness=2)
                )
                
                # Add accuracy text to the frame if we have enough training images and full body is visible
                if self.training_images_count >= 5 and self.current_pose_name and full_body_visible:
                    # Calculate accuracy for current pose
                    accuracy = self.estimator.calculate_pose_accuracy(angles, self.current_pose_name)
                    
                    # Color-coded accuracy display
                    if accuracy > 80:
                        color = (0, 255, 0)  # Green for high accuracy
                    elif accuracy > 60:
                        color = (0, 255, 255)  # Yellow for medium accuracy
                    else:
                        color = (0, 0, 255)  # Red for low accuracy
                        
                    cv2.putText(image, f"{self.current_pose_name} Accuracy: {accuracy:.1f}%", 
                                (20, image.shape[0] - 50), 
                                cv2.FONT_HERSHEY_SIMPLEX, 0.8, color, 2)
                elif not full_body_visible:
                    # Display a message when full body is not visible
                    cv2.putText(image, "Please show full body for pose detection", 
                                (20, image.shape[0] - 50), 
                                cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 2)
                else:
                    # Display a message when full body is not visible
                    cv2.putText(image, "Please show full body for pose detection", 
                                (20, image.shape[0] - 50), 
                                cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 2)
            
            # Display the image
            cv2.imshow("Yoga Pose Analysis", image)
            
            # Initialize key variable before using it
            key = cv2.waitKey(1) & 0xFF
            
            if key == ord('q'):
                break
            elif key == ord('t'):
                # Save training image
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                filename = f"{training_dir}/training_pose_{timestamp}.jpg"
                cv2.imwrite(filename, frame)
                self.training_images_count += 1
                
                # If we have pose landmarks, add them to the current batch
                if results_pose.pose_landmarks:
                    angles = self.estimator.extract_joint_angles(results_pose.pose_landmarks.landmark)
                    self.current_batch.append(angles)
                
                # Emit signal that training count was updated
                self.training_count_updated.emit(self.training_images_count)
                
                # Show feedback that image was saved
                save_feedback = frame.copy()
                cv2.putText(save_feedback, "Image Saved!", (frame.shape[1]//2 - 100, frame.shape[0]//2), 
                           cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0, 255, 0), 3)
                cv2.imshow("Yoga Pose Analysis", save_feedback)
                cv2.waitKey(500)  # Show feedback for half a second
        
        # Clean up resources
        if self.use_esp32_cam:
            self.esp32_cam.release()
        elif cap is not None:
            cap.release()
            
        cv2.destroyAllWindows()
        self.running = False
                
    def stop(self):
        self.running = False

# ---------------------------
# Styled Components
# ---------------------------

class MetricCard(QFrame):
    def __init__(self, title, value="0", unit="", icon=None, color="#1a73e8"):
        super().__init__()
        self.setObjectName("metricCard")
        self.setStyleSheet("""
            #metricCard {
                background-color: white;
                border-radius: 12px;
                padding: 12px;
            }
        """)
        
        # Apply card shadow effect
        shadow = QtWidgets.QGraphicsDropShadowEffect()
        shadow.setBlurRadius(15)
        shadow.setColor(QColor(0, 0, 0, 30))
        shadow.setOffset(0, 2)
        self.setGraphicsEffect(shadow)
        
        layout = QVBoxLayout(self)
        layout.setContentsMargins(16, 16, 16, 16)
        
        # Title and icon
        title_layout = QHBoxLayout()
        title_label = QLabel(title)
        title_label.setFont(QFont("Google Sans", 12))
        title_label.setStyleSheet(f"color: {color};")
        title_layout.addWidget(title_label)
        title_layout.addStretch()
        if icon:
            icon_label = QLabel()
            icon_label.setPixmap(QtGui.QPixmap(icon).scaled(24, 24, Qt.AspectRatioMode.KeepAspectRatio))
            title_layout.addWidget(icon_label)
        layout.addLayout(title_layout)
        
        # Value
        self.value_label = QLabel(value)
        self.value_label.setFont(QFont("Google Sans", 22, QFont.Weight.Medium))
        layout.addWidget(self.value_label)
        
        # Category label (for BMI)
        self.category_label = QLabel()
        self.category_label.setFont(QFont("Google Sans", 10))
        self.category_label.setVisible(False)  # Hidden by default
        layout.addWidget(self.category_label)
        
        # Unit
        if unit:
            unit_label = QLabel(unit)
            unit_label.setFont(QFont("Google Sans", 10))
            unit_label.setStyleSheet("color: #5F6368;")
            layout.addWidget(unit_label)
        
        layout.addStretch()
    
    def update_value(self, value):
        self.value_label.setText(str(value))
        
    def update_category(self, category, color="#1a73e8"):
        """Update the category label (used for BMI)"""
        self.category_label.setText(category)
        self.category_label.setStyleSheet(f"color: {color}; font-weight: bold;")
        self.category_label.setVisible(True)

class ToggleSwitch(QWidget):
    toggled = pyqtSignal(bool)
    
    def __init__(self, parent=None):
        super().__init__(parent)
        self.setFixedSize(50, 25)
        self.is_checked = True
        
    def paintEvent(self, event):
        painter = QtGui.QPainter(self)
        painter.setRenderHint(QtGui.QPainter.RenderHint.Antialiasing)
        
        # Draw background
        if self.is_checked:
            background_color = QColor("#1a73e8")  # Blue when on
        else:
            background_color = QColor("#DADCE0")  # Gray when off
            
        painter.setPen(Qt.PenStyle.NoPen)
        painter.setBrush(background_color)
        painter.drawRoundedRect(0, 0, self.width(), self.height(), self.height() // 2, self.height() // 2)
        
        # Draw handle
        painter.setBrush(QColor(255, 255, 255))
        if self.is_checked:
            painter.drawEllipse(self.width() - 23, 2, self.height() - 4, self.height() - 4)
        else:
            painter.drawEllipse(2, 2, self.height() - 4, self.height() - 4)
    
    def mousePressEvent(self, event):
        self.is_checked = not self.is_checked
        self.toggled.emit(self.is_checked)
        self.update()
        
    def isChecked(self):
        return self.is_checked
        
    def setChecked(self, checked):
        self.is_checked = checked
        self.update()

# Voice assistant integration
class VoiceAssistant:
    def __init__(self):
        self.engine = pyttsx3.init()
        self.voice_enabled = True
        self.message_queue = queue.Queue()
        self.speaking_thread = threading.Thread(target=self._process_speech_queue, daemon=True)
        self.speaking_thread.start()
        
        # Configure voice properties
        self.engine.setProperty('rate', 150)  # Speed of speech
        self.engine.setProperty('volume', 0.8)  # Volume (0.0 to 1.0)
        
        # Try to set a female voice if available
        voices = self.engine.getProperty('voices')
        for voice in voices:
            if "female" in voice.name.lower():
                self.engine.setProperty('voice', voice.id)
                break

    def _process_speech_queue(self):
        """Process speech messages from queue in background thread"""
        while True:
            try:
                message = self.message_queue.get(timeout=0.1)
                if self.voice_enabled:
                    self.engine.say(message)
                    self.engine.runAndWait()
                self.message_queue.task_done()
            except queue.Empty:
                pass
            except Exception as e:
                print(f"Speech error: {e}") 
    def speak(self, message):
        """Add message to speech queue"""
        if self.voice_enabled:
            self.message_queue.put(message)
    
    def toggle_voice(self, enabled=None):
        """Toggle voice on/off or set to specific state"""
        if enabled is None:
            self.voice_enabled = not self.voice_enabled
        else:
            self.voice_enabled = enabled
        return self.voice_enabled

# IndianFoodRecommendations class
class IndianFoodRecommendations(QWidget):
    def __init__(self, bmi=0):
        super().__init__()
        self.setWindowTitle("YogKalp - Indian Food Recommendations")
        self.setMinimumSize(800, 600)
        self.bmi = bmi
        self.setup_ui()
        
    def setup_ui(self):
        layout = QVBoxLayout(self)
        layout.setContentsMargins(24, 24, 24, 24)
        layout.setSpacing(20)
        
        # Header
        header = QLabel("Personalized Indian Food Recommendations")
        header.setFont(QFont("Google Sans", 24, QFont.Weight.Medium))
        layout.addWidget(header)
        
        # BMI Status
        bmi_status = QLabel(f"Your BMI: {self.bmi:.1f}")
        bmi_status.setFont(QFont("Google Sans", 16))
        layout.addWidget(bmi_status)
        
        # Create scroll area for recommendations
        scroll = QScrollArea()
        scroll.setWidgetResizable(True)
        scroll.setStyleSheet("QScrollArea { border: none; }")
        
        content = QWidget()
        content_layout = QVBoxLayout(content)
        
        # Get recommendations based on BMI
        recommendations = self.get_recommendations()

        # Modify the item creation part in the loop where food items are created:
        for category, items in recommendations.items():
            category_frame = QFrame()
            category_frame.setStyleSheet("""
                QFrame {
                    background-color: #f8f9fa;
                    border-radius: 10px;
                    padding: 10px;
                    margin: 5px;
                }
            """)
            category_layout = QVBoxLayout(category_frame)
            
            category_label = QLabel(category)
            category_label.setFont(QFont("Google Sans", 14, QFont.Weight.Medium))
            category_label.setStyleSheet("color: #1a73e8; padding: 5px;")
            category_layout.addWidget(category_label)
            
            # Food items
            for item in items:
                item_frame = QFrame()
                item_frame.setStyleSheet("""
                    QFrame {
                        background-color: white;
                        border-radius: 10px;
                        padding: 15px;
                        margin: 5px;
                    }
                    QFrame:hover {
                        background-color: #f1f3f4;
                    }
                """)
                
                item_layout = QVBoxLayout(item_frame)
                
                # Name and video link in horizontal layout
                name_layout = QHBoxLayout()
                name = QLabel(item['name'])
                name.setFont(QFont("Google Sans", 12, QFont.Weight.Medium))
                name_layout.addWidget(name)
                
                # Add video link button
                if 'video_link' in item:
                    video_btn = QPushButton("Watch Recipe")
                    video_btn.setStyleSheet("""
                        QPushButton {
                            background-color: #FF0000;
                            color: white;
                            border: none;
                            border-radius: 15px;
                            padding: 5px 10px;
                            font-size: 11px;
                        }
                        QPushButton:hover {
                            background-color: #CC0000;
                        }
                    """)
                    video_btn.setCursor(Qt.CursorShape.PointingHandCursor)
                    video_btn.clicked.connect(lambda checked, url=item['video_link']: 
                        QDesktopServices.openUrl(QUrl(url)))
                    name_layout.addWidget(video_btn)
                
                name_layout.addStretch()
                item_layout.addLayout(name_layout)
                
                # Add description
                if 'description' in item:
                    desc = QLabel(item['description'])
                    desc.setWordWrap(True)
                    desc.setStyleSheet("color: #5F6368; margin-top: 5px;")
                    item_layout.addWidget(desc)
                
                # Add benefits
                if 'benefits' in item:
                    benefits = QLabel(f"Benefits: {item['benefits']}")
                    benefits.setWordWrap(True)
                    benefits.setStyleSheet("color: #34A853; margin-top: 5px;")
                    item_layout.addWidget(benefits)
                
                category_layout.addWidget(item_frame)
            
            content_layout.addWidget(category_frame)
        
        content_layout.addStretch()
        scroll.setWidget(content)
        layout.addWidget(scroll)

    def get_recommendations(self):
        if self.bmi < 18.5:
            return {
                "High-Calorie Main Courses": [
                    {
                        "name": "Ghee Rice with Dal Makhani",
                        "description": "Rich in healthy fats and proteins. Made with clarified butter, lentils, and cream.",
                        "benefits": "High in calories, protein, and healthy fats. Helps in weight gain.",
                        "video_link": "https://youtu.be/sOlNWZbcn4M?si=Itaa8AAzFVgQ8Hvy"
                    },
                    {
                        "name": "Shahi Paneer",
                        "description": "Cottage cheese in rich cashew and cream gravy.",
                        "benefits": "Good source of protein and healthy fats.",
                        "video_link": "https://youtu.be/T9hQV22Uezw?si=PbCkLlqeX-pMQDTp"
                    }
                ],
                "Nutritious Snacks": [
                    {
                        "name": "Dry Fruit Ladoo",
                        "description": "Energy-dense balls made with nuts, dates, and ghee.",
                        "benefits": "Rich in healthy fats, proteins, and natural sugars.",
                        "video_link": "https://youtu.be/XehogIkn6TE?si=OEtRPC8R_XXprTNl"
                    },
                    {
                        "name": "Chikki",
                        "description": "Traditional Indian brittle made with jaggery and nuts.",
                        "benefits": "High in calories and essential nutrients.",
                        "video_link": "https://youtu.be/07bpHG1gu_8?si=iGHwTnegiMIyhwyI"
                    }
                ]
            }
        elif self.bmi < 25:
            return {
                "Balanced Main Courses": [
                    {
                        "name": "Dal Tadka with Brown Rice",
                        "description": "Yellow lentils tempered with spices, served with whole grain rice.",
                        "benefits": "Perfect balance of protein and complex carbohydrates.",
                        "video_link": "https://youtu.be/8c_scYUN5uc?si=C2iNprOEj3TvLrmL"
                    },
                    {
                        "name": "Tandoori Roti with Mixed Vegetable Curry",
                        "description": "Whole wheat flatbread with mixed vegetables in a tomato-based gravy.",
                        "benefits": "Rich in fiber and essential nutrients.",
                        "video_link": "https://youtu.be/5Ju3abQS5jY?si=oDqR_D0eIT35e0UH"
                    }
                ],
                "Healthy Snacks": [
                    {
                        "name": "Dhokla",
                        "description": "Steamed fermented rice and chickpea flour cake.",
                        "benefits": "Low in calories, high in protein and probiotics.",
                        "video_link": "https://youtu.be/Vu3HHOfK53A?si=RZjwolVJnXjzdJ_f"
                    },
                    {
                        "name": "Sprouts Bhel",
                        "description": "Mixed sprouts with vegetables and tangy chutneys.",
                        "benefits": "High in protein and fiber, low in calories.",
                        "video_link": "https://youtu.be/OB7tyagqguE?si=b-ntxjXcZb79L8Ti"
                    }
                ]
            }
        else:
            return {
                "Light Main Courses": [
                    {
                        "name": "Vegetable Daliya",
                        "description": "Broken wheat cooked with mixed vegetables and mild spices.",
                        "benefits": "High in fiber, low in calories, keeps you full longer.",
                        "video_link": "https://youtu.be/n4UyBHS1wsk?si=g4H5aWVxvD0TwytS"
                    },
                    {
                        "name": "Moong Dal Khichdi",
                        "description": "Light and digestible rice-lentil preparation with minimal oil.",
                        "benefits": "Easy to digest, protein-rich, low in calories.",
                        "video_link": "https://youtu.be/SYWtizV5oCI?si=ttuuCtebgKFbYQbN"
                    }
                ],
                "Healthy Alternatives": [
                    {
                        "name": "Ragi Dosa",
                        "description": "Crispy crepes made with finger millet flour.",
                        "benefits": "Rich in calcium and fiber, low in calories.",
                        "video_link": "https://youtu.be/I6DgNRcVN84?si=bsTTSc9ItE1pBIpW"
                    },
                    {
                        "name": "Oats Idli",
                        "description": "Steamed savory cakes made with oats and yogurt.",
                        "benefits": "High in fiber and protein, low in calories.",
                        "video_link": "https://youtu.be/OGVcPcfsUPA?si=peim-6cRQvIAvVmD"
                    }
                ]
            }

# User Profile Dialogue Box
class UserProfileDialog(QWidget):
    profile_updated = pyqtSignal(dict)
    
    def __init__(self, parent=None, user_data=None):
        super().__init__(parent)
        self.setWindowTitle("YogKalp - User Profile")
        self.setMinimumSize(600, 600)
        self.user_data = user_data or {}
        self.setup_ui()
        self.center_on_screen()
        self.setWindowFlags(self.windowFlags() | Qt.WindowType.WindowCloseButtonHint)
    
    def center_on_screen(self):
        """Center teh dialog on the screen"""
        screen_geometry = QGuiApplication.primaryScreen().geometry()
        x = (screen_geometry.width() - self.width()) // 2
        y = (screen_geometry.height() - self.height()) // 2
        self.move(x, y)
        
    def setup_ui(self):
        layout = QVBoxLayout(self)
        layout.setContentsMargins(24, 24, 24, 24)
        layout.setSpacing(20)
        
        # Header
        header = QLabel("Your Profile")
        header.setFont(QFont("Google Sans", 24, QFont.Weight.Medium))
        layout.addWidget(header)
        
        # Form layout for user details
        form_card = QFrame()
        form_card.setObjectName("formCard")
        form_card.setStyleSheet("""
            #formCard {
                background-color: white;
                border-radius: 12px;
                padding: 20px;
            }
        """)
        
        # Apply card shadow effect
        shadow = QtWidgets.QGraphicsDropShadowEffect()
        shadow.setBlurRadius(15)
        shadow.setColor(QColor(0, 0, 0, 30))
        shadow.setOffset(0, 2)
        form_card.setGraphicsEffect(shadow)
        
        form_layout = QVBoxLayout(form_card)
        form_layout.setSpacing(16)
        
        # Basic Information Section
        basic_info = QLabel("Basic Information")
        basic_info.setFont(QFont("Google Sans", 16, QFont.Weight.Medium))
        form_layout.addWidget(basic_info)
        
        # Name
        name_layout = QVBoxLayout()
        name_label = QLabel("Full Name")
        name_label.setFont(QFont("Google Sans", 12))
        self.name_input = QLineEdit()
        self.name_input.setMinimumHeight(40)
        self.name_input.setPlaceholderText("Enter your full name")
        self.name_input.setText(self.user_data.get("name", ""))
        name_layout.addWidget(name_label)
        name_layout.addWidget(self.name_input)
        form_layout.addLayout(name_layout)
        
        # Age and Gender in one row
        age_gender_layout = QHBoxLayout()
        
        # Age
        age_layout = QVBoxLayout()
        age_label = QLabel("Age")
        age_label.setFont(QFont("Google Sans", 12))
        self.age_input = QLineEdit()
        self.age_input.setMinimumHeight(40)
        self.age_input.setPlaceholderText("Years")
        self.age_input.setText(str(self.user_data.get("age", "")))
        self.age_input.setValidator(QtGui.QIntValidator(1, 120))
        age_layout.addWidget(age_label)
        age_layout.addWidget(self.age_input)
        age_gender_layout.addLayout(age_layout)
        
        # Gender
        gender_layout = QVBoxLayout()
        gender_label = QLabel("Gender")
        gender_label.setFont(QFont("Google Sans", 12))
        self.gender_input = QtWidgets.QComboBox()
        self.gender_input.setMinimumHeight(40)
        self.gender_input.addItems(["Select", "Male", "Female", "Other"])
        gender_index = self.gender_input.findText(self.user_data.get("gender", "Select"))
        self.gender_input.setCurrentIndex(gender_index if gender_index >= 0 else 0)
        gender_layout.addWidget(gender_label)
        gender_layout.addWidget(self.gender_input)
        age_gender_layout.addLayout(gender_layout)
        
        form_layout.addLayout(age_gender_layout)
        
        # Health Information Section
        health_info = QLabel("Health Information")
        health_info.setFont(QFont("Google Sans", 16, QFont.Weight.Medium))
        form_layout.addWidget(health_info)
        
        # Height and Weight in one row
        hw_layout = QHBoxLayout()
        
        # Height
        height_layout = QVBoxLayout()
        height_label = QLabel("Height")
        height_label.setFont(QFont("Google Sans", 12))
        self.height_input = QLineEdit()
        self.height_input.setMinimumHeight(40)
        self.height_input.setPlaceholderText("cm")
        self.height_input.setText(str(self.user_data.get("height", "")))
        self.height_input.setValidator(QtGui.QDoubleValidator(50, 250, 1))
        height_layout.addWidget(height_label)
        height_layout.addWidget(self.height_input)
        hw_layout.addLayout(height_layout)
        
        # Weight
        weight_layout = QVBoxLayout()
        weight_label = QLabel("Weight")
        weight_label.setFont(QFont("Google Sans", 12))
        self.weight_input = QLineEdit()
        self.weight_input.setMinimumHeight(40)
        self.weight_input.setPlaceholderText("kg")
        self.weight_input.setText(str(self.user_data.get("weight", "")))
        self.weight_input.setValidator(QtGui.QDoubleValidator(1, 500, 1))
        weight_layout.addWidget(weight_label)
        weight_layout.addWidget(self.weight_input)
        hw_layout.addLayout(weight_layout)
        
        form_layout.addLayout(hw_layout)
        
        # Fitness Goals
        goals_layout = QVBoxLayout()
        goals_label = QLabel("Fitness Goals")
        goals_label.setFont(QFont("Google Sans", 12))
        self.goals_input = QLineEdit()
        self.goals_input.setMinimumHeight(40)
        self.goals_input.setPlaceholderText("e.g., Weight loss, Flexibility, Stress reduction")
        self.goals_input.setText(self.user_data.get("goals", ""))
        goals_layout.addWidget(goals_label)
        goals_layout.addWidget(self.goals_input)
        form_layout.addLayout(goals_layout)
        
        layout.addWidget(form_card)
        buttons_layout = QHBoxLayout()
        
        # Cancel button
        self.cancel_btn = QPushButton("Cancel")
        self.cancel_btn.setFixedHeight(50)
        self.cancel_btn.setFont(QFont("Google Sans", 14))
        self.cancel_btn.setStyleSheet("""
            QPushButton {
                background-color: #DADCE0;
                color: #202124;
            }
            QPushButton:hover {
                background-color: #C0C0C0;
            }
        """)
        self.cancel_btn.clicked.connect(self.close)
        buttons_layout.addWidget(self.cancel_btn)
        
        # Save button
        self.save_btn = QPushButton("Save Profile")
        self.save_btn.setFixedHeight(50)
        self.save_btn.setFont(QFont("Google Sans", 14))
        self.save_btn.clicked.connect(self.save_profile)
        buttons_layout.addWidget(self.save_btn)
        layout.addLayout(buttons_layout)
    
    def save_profile(self):
        # Validate inputs
        if not self.name_input.text():
            QMessageBox.warning(self, "Incomplete Profile", "Please enter your name.")
            return
            
        if self.gender_input.currentText() == "Select":
            QMessageBox.warning(self, "Incomplete Profile", "Please select your gender.")
            return
            
        # Collect user data
        user_data = {
            "name": self.name_input.text(),
            "age": self.age_input.text(),
            "gender": self.gender_input.currentText(),
            "height": self.height_input.text(),
            "weight": self.weight_input.text(),
            "goals": self.goals_input.text()
        }
        
        # Save to file
        try:
            os.makedirs("user_data", exist_ok=True)
            with open("user_data/profile.json", "w") as f:
                json.dump(user_data, f)
            
            # Emit signal that profile was updated
            self.profile_updated.emit(user_data)
            
            QMessageBox.information(self, "Profile Saved", "Your profile has been saved successfully!")
            self.close()
        except Exception as e:
            QMessageBox.critical(self, "Error", f"Could not save profile: {str(e)}")

class ModernYogaApp(QMainWindow):
    def __init__(self):
        super().__init__()
        self.setWindowTitle("YogKalp")
        self.setStyleSheet("""
            QMainWindow {
                background-color: #F8F9FA;
                font-family: 'Google Sans', 'Segoe UI', 'Arial';
            }
            QPushButton {
                background-color: #1a73e8;
                color: white;
                border: none;
                border-radius: 24px;
                padding: 12px 24px;
                font-size: 14px;
                font-weight: 500;
            }
            QPushButton:hover {
                background-color: #1765cc;
            }
            QPushButton:pressed {
                background-color: #185abc;
            }
            QLineEdit {
                border: 1px solid #DADCE0;
                border-radius: 8px;
                padding: 12px;
                background-color: white;
                font-size: 14px;
            }
            QLineEdit:focus {
                border: 2px solid #1a73e8;
            }
            QLabel {
                color: #202124;
            }
            QScrollArea {
                border: none;
                background-color: transparent;
            }
        """)
        self.resize(1000, 700)
        self.estimator = PoseEstimator()
        self.camera_thread = None
        self.training_images_count = 0
        self.current_accuracy = 0.0
        self.current_pose_name = ""
        self.current_batch_complete = False  # Track if current batch is complete
        
        # Initialize user profile data
        self.user_profile = {}
        
        # Initialize heart rate alert flag
        self.heart_rate_alert_shown = False
        
        # Setup UI only once
        self.setup_ui()
        
        # Load user profile after UI setup
        self.load_user_profile()
        
        self.poses_trained_value.setText(str(len(self.estimator.named_poses)))    
        
        # Initialize voice assistant
        self.voice_assistant = VoiceAssistant()
        
        # Welcome message with name if available
        welcome_msg = "Welcome to YogKalp. Your personal yoga and health assistant."
        if "name" in self.user_profile and self.user_profile["name"]:
            welcome_msg = f"Welcome {self.user_profile['name']} to YogKalp. Your personal yoga and health assistant."
        self.voice_assistant.speak(welcome_msg)
            
        # Update Timer
        self.timer = QtCore.QTimer()
        self.timer.timeout.connect(self.update_data)
        self.timer.start(1000)
        
        # Calorie calcuation timer
        self.calorie_timer = QTimer()
        self.calorie_timer.timeout.connect(self.update_calories_burned)
        self.calorie_timer.start(5000)  # Updates every 5 seconds
        
    def setup_ui(self):
        central_widget = QWidget()
        main_layout = QVBoxLayout(central_widget)
        main_layout.setContentsMargins(24, 24, 24, 24)
        main_layout.setSpacing(24)
        
        # Header
        header = QWidget()
        header_layout = QHBoxLayout(header)
        header_layout.setContentsMargins(0, 0, 0, 0)
        
        # Replace text title with logo
        logo_label = QLabel()
        logo_pixmap = QPixmap("c:/Users/sriva/OneDrive/Desktop/YogKalp/YogKalp_logo.jpg")
        logo_label.setPixmap(logo_pixmap.scaled(180, 60, Qt.AspectRatioMode.KeepAspectRatio, Qt.TransformationMode.SmoothTransformation))
        header_layout.addWidget(logo_label)
        
        header_layout.addStretch()
        
        # Profile section
        profile_btn = QPushButton("Profile")
        profile_btn.setFixedSize(QSize(100, 40))
        profile_btn.clicked.connect(self.show_profile)
        header_layout.addWidget(profile_btn)
        
        main_layout.addWidget(header)
        
        # User inputs
        input_card = QFrame()
        input_card.setObjectName("inputCard")
        input_card.setStyleSheet("""
            #inputCard {
                background-color: white;
                border-radius: 12px;
            }
        """)
        
        # Apply card shadow effect
        shadow = QtWidgets.QGraphicsDropShadowEffect()
        shadow.setBlurRadius(15)
        shadow.setColor(QColor(0, 0, 0, 30))
        shadow.setOffset(0, 2)
        input_card.setGraphicsEffect(shadow)
        
        input_layout = QVBoxLayout(input_card)
        input_layout.setContentsMargins(20, 20, 20, 20)
        
        input_title = QLabel("Your Information")
        input_title.setFont(QFont("Google Sans", 16, QFont.Weight.Medium))
        input_layout.addWidget(input_title)
        
        input_fields = QHBoxLayout()
        input_fields.setSpacing(16)
        
        self.weight_input = QLineEdit()
        self.weight_input.setPlaceholderText("Weight (kg)")
        self.height_input = QLineEdit()
        self.height_input.setPlaceholderText("Height (cm)")
        
        # Add food recommendations button
        self.food_rec_btn = QPushButton("View Food Recommendations")
        self.food_rec_btn.clicked.connect(self.show_food_recommendations)
        input_layout.addWidget(self.food_rec_btn)
        
        input_fields.addWidget(self.weight_input)
        input_fields.addWidget(self.height_input)
        input_layout.addLayout(input_fields)
        
        main_layout.addWidget(input_card)
        
        # Scroll area for metrics
        scroll_area = QScrollArea()
        scroll_area.setWidgetResizable(True)
        scroll_area.setFrameShape(QtWidgets.QFrame.Shape.NoFrame)
        
        scroll_content = QWidget()
        metrics_layout = QVBoxLayout(scroll_content)
        metrics_layout.setContentsMargins(0, 0, 0, 0)
        metrics_layout.setSpacing(20)
        
        # Metrics section title
        metrics_title = QLabel("Today's Metrics")
        metrics_title.setFont(QFont("Google Sans", 18, QFont.Weight.Medium))
        metrics_layout.addWidget(metrics_title)
        
        # Metrics cards
        metrics_grid = QGridLayout()
        metrics_grid.setContentsMargins(0, 0, 0, 0)
        metrics_grid.setSpacing(16)
        
        # BMI Card
        self.bmi_card = MetricCard("BMI", "0", "kg/m²", color="#4285F4")
        metrics_grid.addWidget(self.bmi_card, 0, 0)
        
        # Heart Rate Card
        self.heart_card = MetricCard("Heart Rate", "0", "bpm", color="#EA4335")
        metrics_grid.addWidget(self.heart_card, 0, 1)
        
        # Calories burnt Card
        self.calories_card = MetricCard("Calories Burned", "0", "kcal", color="#34A853")
        metrics_grid.addWidget(self.calories_card,0, 2)
        
        # SpO2 Level Card
        self.spo2_card = MetricCard("SpO2 Level", "0", "%", color="#9C27B0")
        metrics_grid.addWidget(self.spo2_card, 1, 0)
        
        # Cardio/Strength Training Card (renamed)
        self.strength_card = MetricCard("Cardio/Strength Training", "0", "reps", color="#FF9800")
        metrics_grid.addWidget(self.strength_card, 1, 1)
        
        # Add this line to create the steps_value attribute
        self.steps_value = self.strength_card
        
        # Temperature Card
        temp_card = QFrame()
        temp_card.setObjectName("metricCard")
        temp_card.setStyleSheet("""
            #metricCard {
                background-color: white;
                border-radius: 12px;
                padding: 12px;
            }
        """)

        # Apply card shadow effect
        shadow = QtWidgets.QGraphicsDropShadowEffect()
        shadow.setBlurRadius(15)
        shadow.setColor(QColor(0, 0, 0, 30))
        shadow.setOffset(0, 2)
        temp_card.setGraphicsEffect(shadow)

        temp_layout = QVBoxLayout(temp_card)
        temp_layout.setContentsMargins(16, 16, 16, 16)

        temp_title = QLabel("Body Temperature")
        temp_title.setFont(QFont("Google Sans", 12))
        temp_title.setStyleSheet("color: #673AB7;")
        temp_layout.addWidget(temp_title)

        temp_values = QHBoxLayout()

        pre_temp_layout = QVBoxLayout()
        pre_temp_label = QLabel("Pre-workout (Body temperature)")
        pre_temp_label.setFont(QFont("Google Sans", 10))
        pre_temp_label.setStyleSheet("color: #5F6368;")
        self.pre_temp_value = QLabel("0.00°C")
        self.pre_temp_value.setFont(QFont("Google Sans", 18, QFont.Weight.Medium))
        pre_temp_layout.addWidget(pre_temp_label)
        pre_temp_layout.addWidget(self.pre_temp_value)

        post_temp_layout = QVBoxLayout()
        post_temp_label = QLabel("Body heat (Post-workout)")
        post_temp_label.setFont(QFont("Google Sans", 10))
        post_temp_label.setStyleSheet("color: #5F6368;")
        self.post_temp_value = QLabel("0.00°C")
        self.post_temp_value.setFont(QFont("Google Sans", 18, QFont.Weight.Medium))
        post_temp_layout.addWidget(post_temp_label)
        post_temp_layout.addWidget(self.post_temp_value)

        temp_values.addLayout(pre_temp_layout)
        temp_values.addLayout(post_temp_layout)

        temp_layout.addLayout(temp_values)
        
        metrics_grid.addWidget(temp_card, 2, 0, 1, 2)
        
        # Add Pose Accuracy Card
        self.accuracy_card = QFrame()
        self.accuracy_card.setObjectName("metricCard")
        self.accuracy_card.setStyleSheet("""
            #metricCard {
                background-color: white;
                border-radius: 12px;
                padding: 12px;
            }
        """)
        
        # Apply card shadow effect
        shadow = QtWidgets.QGraphicsDropShadowEffect()
        shadow.setBlurRadius(15)
        shadow.setColor(QColor(0, 0, 0, 30))
        shadow.setOffset(0, 2)
        self.accuracy_card.setGraphicsEffect(shadow)
        
        accuracy_layout = QVBoxLayout(self.accuracy_card)
        accuracy_layout.setContentsMargins(16, 16, 16, 16)
        
        # Create header with title and toggle switch
        accuracy_header = QHBoxLayout()
        
        accuracy_title = QLabel("Pose Accuracy")
        accuracy_title.setFont(QFont("Google Sans", 12))
        accuracy_title.setStyleSheet("color: #7B1FA2;")  # Purple color
        accuracy_header.addWidget(accuracy_title)
        
        accuracy_header.addStretch()
        
         # Variables to track feedback counts
        self.low_accuracy_feedback_count = 0
        self.medium_accuracy_feedback_count = 0
        self.last_accuracy_level = "high"  # Track the last accuracy level
        
        # Add palm detection toggle with label
        palm_toggle_layout = QHBoxLayout()
        palm_toggle_label = QLabel("Palm Detection:")
        palm_toggle_label.setFont(QFont("Google Sans", 10))
        palm_toggle_label.setStyleSheet("color: #5F6368;")
        palm_toggle_layout.addWidget(palm_toggle_label)
        
        self.palm_toggle = ToggleSwitch()
        self.palm_toggle.setChecked(False)
        self.palm_toggle.toggled.connect(self.toggle_palm_detection)
        palm_toggle_layout.addWidget(self.palm_toggle)
        
        accuracy_header.addLayout(palm_toggle_layout)
        
        accuracy_layout.addLayout(accuracy_header)
        
        # Current accuracy value with pose name
        self.pose_accuracy_value = QLabel("Training required")
        self.pose_accuracy_value.setFont(QFont("Google Sans", 22, QFont.Weight.Medium))
        accuracy_layout.addWidget(self.pose_accuracy_value)
        
        # Add explanation text
        self.accuracy_info = QLabel("Capture at least 5 training images to see pose accuracy")
        self.accuracy_info.setFont(QFont("Google Sans", 10))
        self.accuracy_info.setStyleSheet("color: #5F6368;")
        self.accuracy_info.setWordWrap(True)
        accuracy_layout.addWidget(self.accuracy_info)
        
        metrics_grid.addWidget(self.accuracy_card, 3, 0, 1, 2)
        
        metrics_layout.addLayout(metrics_grid)
        
        # Training Images Card
        training_card = QFrame()
        training_card.setObjectName("metricCard")
        training_card.setStyleSheet("""
            #metricCard {
                background-color: white;
                border-radius: 12px;
                padding: 12px;
            }
        """)
        
        # Apply card shadow effect
        shadow = QtWidgets.QGraphicsDropShadowEffect()
        shadow.setBlurRadius(15)
        shadow.setColor(QColor(0, 0, 0, 30))
        shadow.setOffset(0, 2)
        training_card.setGraphicsEffect(shadow)
        
        training_layout = QVBoxLayout(training_card)
        training_layout.setContentsMargins(16, 16, 16, 16)
        
        training_title = QLabel("Training Progress")
        training_title.setFont(QFont("Google Sans", 12))
        training_title.setStyleSheet("color: #00897B;")
        training_layout.addWidget(training_title)
        
        # Modify the training card to include poses trained count
        training_info = QHBoxLayout()
        
         # Add voice assistant toggle to header
        header_layout = QHBoxLayout(header)
        header_layout.setContentsMargins(0, 0, 0, 0)
        
        title = QLabel("YogKalp")
        title.setFont(QFont("Google Sans", 24, QFont.Weight.Medium))
        header_layout.addWidget(title)
        
        header_layout.addStretch()
        
        # Add voice assistant toggle
        voice_toggle_layout = QHBoxLayout()
        voice_toggle_label = QLabel("Voice Assistant:")
        voice_toggle_label.setFont(QFont("Google Sans", 10))
        voice_toggle_layout.addWidget(voice_toggle_label)
        
        self.voice_toggle = ToggleSwitch()
        self.voice_toggle.setChecked(True)  # Voice enabled by default
        self.voice_toggle.toggled.connect(self.toggle_voice_assistant)
        voice_toggle_layout.addWidget(self.voice_toggle)
        
        header_layout.addLayout(voice_toggle_layout)
        
        # Profile section placeholder
        profile_btn = QPushButton("Profile")
        profile_btn.setFixedSize(QSize(100, 40))
        header_layout.addWidget(profile_btn)
        
        # Training images count
        training_count_layout = QVBoxLayout()
        training_count_label = QLabel("Captured Images")
        training_count_label.setFont(QFont("Google Sans", 10))
        training_count_label.setStyleSheet("color: #5F6368;")
        self.training_count_value = QLabel("0")
        self.training_count_value.setFont(QFont("Google Sans", 22, QFont.Weight.Medium))
        training_count_layout.addWidget(training_count_label)
        training_count_layout.addWidget(self.training_count_value)
        
        # Add poses trained count
        poses_trained_layout = QVBoxLayout()
        poses_trained_label = QLabel("Poses Trained")
        poses_trained_label.setFont(QFont("Google Sans", 10))
        poses_trained_label.setStyleSheet("color: #5F6368;")
        self.poses_trained_value = QLabel("0")
        self.poses_trained_value.setFont(QFont("Google Sans", 22, QFont.Weight.Medium))
        poses_trained_layout.addWidget(poses_trained_label)
        poses_trained_layout.addWidget(self.poses_trained_value)
        
        # Current pose name display
        pose_name_layout = QVBoxLayout()
        pose_name_label = QLabel("Current Pose")
        pose_name_label.setFont(QFont("Google Sans", 10))
        pose_name_label.setStyleSheet("color: #5F6368;")
        self.pose_name_value = QLabel("None")
        self.pose_name_value.setFont(QFont("Google Sans", 18, QFont.Weight.Medium))
        pose_name_layout.addWidget(pose_name_label)
        pose_name_layout.addWidget(self.pose_name_value)
        
        training_info.addLayout(training_count_layout)
        training_info.addLayout(poses_trained_layout)
        training_info.addLayout(pose_name_layout)
        
        # Instructions
        self.training_instructions = QLabel("Press 'T' while camera is active to capture a training image")
        self.training_instructions.setFont(QFont("Google Sans", 10))
        self.training_instructions.setStyleSheet("color: #5F6368;")
        self.training_instructions.setWordWrap(True)
        
        training_info.addLayout(training_count_layout)
        training_info.addLayout(pose_name_layout)
        
        training_layout.addLayout(training_info)
        training_layout.addWidget(self.training_instructions)
        
        metrics_layout.addWidget(training_card)
     
               # Camera section
        camera_section = QVBoxLayout()
        camera_title = QLabel("Pose Analysis")
        camera_title.setFont(QFont("Google Sans", 18, QFont.Weight.Medium))
        camera_section.addWidget(camera_title)
        
        # Add ESP32-CAM controls - modified to place toggle next to text
        esp32_cam_layout = QHBoxLayout()
        esp32_cam_label = QLabel("Use YogKalp Cam")
        esp32_cam_label.setFont(QFont("Google Sans", 10))
        esp32_cam_layout.addWidget(esp32_cam_label)

        self.esp32_cam_toggle = ToggleSwitch()
        self.esp32_cam_toggle.setChecked(False)
        esp32_cam_layout.addWidget(self.esp32_cam_toggle)
        
        # Add spacer to push toggle and label to the left
        esp32_cam_layout.addStretch()
        
        camera_section.addLayout(esp32_cam_layout)
        
        self.start_btn = QPushButton("Start Camera")
        self.start_btn.clicked.connect(self.toggle_camera)
        self.start_btn.setFixedHeight(50)
        self.start_btn.setFont(QFont("Google Sans", 14))
        camera_section.addWidget(self.start_btn)
        metrics_layout.addLayout(camera_section)
        
        # Add everything to scroll area
        scroll_area.setWidget(scroll_content)
        main_layout.addWidget(scroll_area)
        
        self.setCentralWidget(central_widget)

    def update_data(self):
        # Initialize variables for later use
        heart_rate = 0
        post_temp = 0
        strength_count = 0
        
        # Update health metrics from ESP32
        try:
            # Update heart rate
            if "heart_rate" in esp_data and esp_data["heart_rate"] > 0:
                heart_rate = esp_data["heart_rate"]  # Store for later use
                self.heart_card.update_value(str(heart_rate))
                
                # Check for high heart rate and show alert if needed
                if heart_rate > 90 and not self.heart_rate_alert_shown:
                    self.heart_rate_alert_shown = True
                    QMessageBox.warning(self, "High Heart Rate", 
                                        f"Your heart rate is {heart_rate} BPM, which is elevated. Consider taking a break.")
                    self.voice_assistant.speak(f"Warning. Your heart rate is {heart_rate} beats per minute, which is elevated. Consider taking a break.")
            
            # Update SpO2
            if "spo2" in esp_data and esp_data["spo2"] > 0:
                self.spo2_card.update_value(str(esp_data["spo2"]))
            
            # Update temperature
            if "body_temp_pre" in esp_data and esp_data["body_temp_pre"] > 0:
                self.pre_temp_value.setText(f"{esp_data['body_temp_pre']:.1f}°C")
                
            # Update post-workout temperature
            if "body_temp_post" in esp_data and esp_data["body_temp_post"] > 0:
                post_temp = esp_data["body_temp_post"]  # Store for later use
                self.post_temp_value.setText(f"{post_temp:.1f}°C")
            
            # Update steps from MPU6050
            if "steps" in esp_data:
                strength_count = esp_data["steps"]  # Store for later use
                self.steps_value.update_value(str(strength_count))
                print(f"Updating steps display to: {strength_count}")
    
            # Update sensor status indicators commented out
            # if "max30102_status" in esp_data:
            #     self.update_sensor_status("MAX30102", esp_data["max30102_status"])
                
        except Exception as e:
            print(f"Error updating data: {e}")
        
        # FIXED: BMI calculation moved outside the exception handler and properly indented
        # Calculate BMI if weight and height are provided
        try:
            bmi = 0
            if self.weight_input.text() and self.height_input.text():
                weight = float(self.weight_input.text())
                height = float(self.height_input.text()) / 100  # Convert cm to m
                bmi = weight / (height * height)
                self.bmi_card.update_value(f"{bmi:.1f}")
                
                # Update BMI category
                if bmi < 18.5:
                    self.bmi_card.update_category("Underweight", "#FB8C00")
                elif bmi < 25:
                    self.bmi_card.update_category("Normal", "#4CAF50")
                elif bmi < 30:
                    self.bmi_card.update_category("Overweight", "#FFC107")
                else:
                    self.bmi_card.update_category("Obese", "#F44336")
                
                # Calculate estimated calories burned based on multiple factors
                if heart_rate > 0 and weight > 0:
                    # Base metabolic rate (BMR) factor based on heart rate
                    hr_factor = 1.0
                    if heart_rate > 120:
                        hr_factor = 1.8
                    elif heart_rate > 100:
                        hr_factor = 1.5
                    elif heart_rate > 80:
                        hr_factor = 1.2
                    
                    # BMI factor (higher BMI = more calories burned for same activity)
                    bmi_factor = 1.0
                    if bmi > 30:
                        bmi_factor = 1.2
                    elif bmi > 25:
                        bmi_factor = 1.1
                    elif bmi < 18.5:
                        bmi_factor = 0.9
                    
                    # Temperature factor (higher body heat = more calories burned)
                    temp_factor = 1.0
                    if post_temp > 37.5:
                        temp_factor = 1.15
                    elif post_temp > 37.0:
                        temp_factor = 1.1
                    
                    # Activity factor based on strength training only now
                    activity_factor = 1.0 + (strength_count / 100)
                    
                    # Calculate calories: weight * combined factors * time (30 min)
                    calories = weight * hr_factor * bmi_factor * temp_factor * activity_factor * 0.5
                    self.calorie_card.update_value(f"{int(calories)}")
        except ValueError as e:
            print(f"Error calculating BMI: {e}")
        
        # Update pose accuracy display
        try:
            if self.training_images_count >= 5 and self.current_pose_name:
                self.pose_accuracy_value.setText(f"{self.current_pose_name}: {self.current_accuracy:.1f}%")
                
                # Update accuracy info text based on accuracy level
                if self.current_accuracy > 80:
                    self.accuracy_info.setText("Excellent form! Keep it up.")
                    self.accuracy_info.setStyleSheet("color: #4CAF50;")  # Green
                elif self.current_accuracy > 60:
                    self.accuracy_info.setText("Good form. Minor adjustments needed.")
                    self.accuracy_info.setStyleSheet("color: #FFC107;")  # Yellow/Orange
                else:
                    self.accuracy_info.setText("Form needs improvement. Follow the guide.")
                    self.accuracy_info.setStyleSheet("color: #F44336;")  # Red
            else:
                self.pose_accuracy_value.setText("Training required")
                self.accuracy_info.setText("Capture at least 5 training images to see pose accuracy")
                self.accuracy_info.setStyleSheet("color: #5F6368;")  # Gray
        except Exception as e:
            print(f"Error updating pose accuracy: {e}")

    def update_calories_burned(self):
        """Calculate and update calories burned based on current session data"""
        try:
            # Get current values
            heart_rate = esp_data.get("heart_rate", 0)
            body_temp = max(esp_data.get("body_temp_pre", 37.0), esp_data.get("body_temp_post", 37.0))
            strength_count = esp_data.get("steps", 0)
            
            # Only calculate if we have valid heart rate data and user input
            if heart_rate > 40 and self.weight_input.text():
                # Get user data
                weight = float(self.weight_input.text())
                height = float(self.height_input.text()) if self.height_input.text() else 170
                
                # Calculate BMI
                height_m = height / 100  # Convert cm to m
                bmi = weight / (height_m * height_m)
                
                # Heart rate factor (higher HR = more calories burned)
                hr_factor = 1.0
                if heart_rate > 120:
                    hr_factor = 1.8
                elif heart_rate > 100:
                    hr_factor = 1.5
                elif heart_rate > 80:
                    hr_factor = 1.2
                
                # BMI factor (higher BMI = more calories burned for same activity)
                bmi_factor = 1.0
                if bmi > 30:
                    bmi_factor = 1.2
                elif bmi > 25:
                    bmi_factor = 1.1
                elif bmi < 18.5:
                    bmi_factor = 0.9
                
                # Temperature factor (higher body heat = more calories burned)
                temp_factor = 1.0
                if body_temp > 37.5:
                    temp_factor = 1.15
                elif body_temp > 37.0:
                    temp_factor = 1.1
                
                # Activity factor based on strength training/steps
                activity_factor = 1.0 + (strength_count / 100)
                
                # Calculate calories: weight * combined factors * time (minutes since last update)
                if not hasattr(self, 'last_calorie_update'):
                    self.last_calorie_update = time.time()
                    self.total_calories = 0
                
                current_time = time.time()
                minutes_elapsed = (current_time - self.last_calorie_update) / 60
                
                # MET value for yoga (3-6 depending on intensity)
                yoga_met = 4.0
                
                # Calories burned = MET * weight (kg) * time (hours) * adjustment factors
                calories = yoga_met * weight * (minutes_elapsed / 60) * hr_factor * bmi_factor * temp_factor * activity_factor
                
                # Add to total
                self.total_calories += calories
                
                # Update the calories display
                self.calories_card.update_value(f"{int(self.total_calories)}")
                
                # Update last update time
                self.last_calorie_update = current_time
                
        except Exception as e:
            print(f"Error calculating calories: {e}")
            
    def show_heart_rate_alert(self):
        """Show alert for high heart rate with recommended yoga poses"""
        # Create message box with yoga pose recommendations
        msg = QMessageBox(self)
        msg.setIcon(QMessageBox.Icon.Warning)
        msg.setWindowTitle("Heart Rate Alert")
        
        # Set message with recommended poses
        message = (
            "<h3>Irregular Heart Rate Detected!</h3>"
            "<p>Your heart rate is elevated. Consider practicing these calming yoga poses:</p>"
            "<ul>"
            "<li><b>Lotus Pose (Padmasana)</b>: Sit cross-legged with feet on opposite thighs</li>"
            "<li><b>Child's Pose (Balasana)</b>: Kneel and bend forward with arms extended</li>"
            "<li><b>Corpse Pose (Savasana)</b>: Lie flat on your back with arms at sides</li>"
            "</ul>"
            "<p>Remember to breathe deeply and slowly while practicing these poses.</p>"
        )
        msg.setText(message)
        
        # Add buttons
        msg.setStandardButtons(QMessageBox.StandardButton.Ok)
        
        # Make the dialog non-modal so it doesn't block the app
        msg.setModal(False)
        
        # Show the message box
        msg.show()
        
    def update_accuracy(self, accuracy, pose_name):
        """Update the pose accuracy display and provide voice feedback"""
        self.current_accuracy = accuracy
        self.current_pose_name = pose_name
        
        # Update accuracy display
        self.pose_accuracy_value.setText(f"{pose_name}: {accuracy:.1f}%")
        
        # Update accuracy info text based on accuracy level
        current_level = ""
        if accuracy > 80:
            self.accuracy_info.setText("Excellent form! Keep it up.")
            self.accuracy_info.setStyleSheet("color: #4CAF50;")  # Green
            current_level = "high"
        elif accuracy > 60:
            self.accuracy_info.setText("Good form. Minor adjustments needed.")
            self.accuracy_info.setStyleSheet("color: #FFC107;")  # Yellow/Orange
            current_level = "medium"
            
            # Only provide voice feedback twice for medium accuracy
            if self.last_accuracy_level != "medium" and self.medium_accuracy_feedback_count < 2:
                self.voice_assistant.speak(f"Your {pose_name} form needs minor adjustments.")
                self.medium_accuracy_feedback_count += 1
        else:
            self.accuracy_info.setText("Form needs improvement. Follow the guide.")
            self.accuracy_info.setStyleSheet("color: #F44336;")  # Red
            current_level = "low"
            
            # Only provide voice feedback twice for low accuracy
            if self.last_accuracy_level != "low" and self.low_accuracy_feedback_count < 2:
                self.voice_assistant.speak(f"Your {pose_name} form needs significant improvement. Please check the guide.")
                self.low_accuracy_feedback_count += 1
        
        # Reset counters if level changes
        if current_level != self.last_accuracy_level:
            if current_level == "high":
                # Reset counters when returning to high accuracy
                self.medium_accuracy_feedback_count = 0
                self.low_accuracy_feedback_count = 0
            self.last_accuracy_level = current_level
    
    def toggle_camera(self):
        if self.camera_thread and self.camera_thread.running:
            # Stop camera
            self.camera_thread.stop()
            self.camera_thread.wait()  # Wait for thread to finish
            self.camera_thread = None
            self.start_btn.setText("Start Camera")
            self.start_btn.setStyleSheet("""
                background-color: #1a73e8;
                color: white;
                border: none;
                border-radius: 24px;
                padding: 12px 24px;
                font-size: 14px;
                font-weight: 500;
            """)
        else:
            # Start camera using QThread
            self.camera_thread = CameraThread(self.estimator)
            
            # Set initial palm detection state from toggle
            self.camera_thread.set_palm_detection_enabled(self.palm_toggle.isChecked())
            
            # Set ESP32-CAM options
            use_esp32_cam = self.esp32_cam_toggle.isChecked()
            if use_esp32_cam:
                # Use the hardcoded URL from ESP32CameraReceiver class
                self.camera_thread.set_esp32_cam_enabled(True)
                
            # Connect signals to slots
            self.camera_thread.training_count_updated.connect(self.update_training_count)
            self.camera_thread.accuracy_updated.connect(self.update_accuracy)
            self.camera_thread.model_updated.connect(self.update_pose_list)
            self.camera_thread.pose_count_updated.connect(self.update_poses_trained)
            self.camera_thread.camera_error.connect(self.show_camera_error)  # Connect new signal
            
            # Start the thread
            self.camera_thread.start()
            
            # Update button text
            self.start_btn.setText("Stop Camera")
            self.start_btn.setStyleSheet("""
                background-color: #EA4335;
                color: white;
                border: none;
                border-radius: 24px;
                padding: 12px 24px;
                font-size: 14px;
                font-weight: 500;
            """)
            
    def show_camera_error(self, error_message):
        """Show popup for camera connection errors"""
        msg = QMessageBox(self)
        msg.setIcon(QMessageBox.Icon.Warning)
        msg.setWindowTitle("Camera Connection Error")
        msg.setText(error_message)
        msg.setStandardButtons(QMessageBox.StandardButton.Ok)
        msg.setModal(False)  # Non-modal dialog
        msg.show()
        
        # Also provide voice feedback
        self.voice_assistant.speak("Camera connection error. " + error_message)
            
    def update_pose_list(self):
        """
        Update the UI when the pose list changes
        """
        # Update pose name dropdown or list if we have one
        # For now, just update the current pose name display
        if self.current_pose_name:
            self.pose_name_value.setText(self.current_pose_name)
            
            # Update instructions based on training progress
            if self.training_images_count >= 5:
                self.training_instructions.setText("Continue capturing poses or switch to a new pose")
            else:
                self.training_instructions.setText(f"Capture {5 - self.training_images_count} more images to complete this pose")
    
    def update_training_count(self, count):
        """
        Update the training count and prompt for pose name if needed
        """
        self.training_images_count = count
        self.training_count_value.setText(str(count))
        
        # Check if we've reached a multiple of 5
        if count > 0 and count % 5 == 0:
            # Only prompt for pose name if we haven't already for this batch
            if not hasattr(self, 'current_batch_complete') or not self.current_batch_complete:
                self.current_batch_complete = True
                # Prompt for pose name
                name, ok = QInputDialog.getText(self, "Name Your Pose", 
                                                "Enter a name for this pose batch:", 
                                                QLineEdit.EchoMode.Normal)
                if ok and name:
                    self.current_pose_name = name
                    self.pose_name_value.setText(name)
                    
                    # Save the current batch with this name
                    if self.camera_thread:
                        self.camera_thread.set_pose_name(name)
                        self.camera_thread.save_current_batch(name)
        elif count % 5 != 0:
            # Reset the batch completion flag when not at a multiple of 5
            self.current_batch_complete = False
    
    def update_poses_trained(self, count):
        """Update the poses trained count display"""
        self.poses_trained_value.setText(str(count))
    
    def toggle_palm_detection(self, enabled):
        """Enable or disable palm detection feature"""
        if self.camera_thread and self.camera_thread.running:
            self.camera_thread.set_palm_detection_enabled(enabled)
            
        # Update the instructions text based on the toggle state
        if enabled:
            self.training_instructions.setText("Press 'T' or show open palm to capture training images")
        else:
            self.training_instructions.setText("Press 'T' to capture training images (palm detection disabled)")

    def toggle_voice_assistant(self, enabled):
        """Enable or disable voice assistant"""
        self.voice_assistant.toggle_voice(enabled)
        if enabled:
            self.voice_assistant.speak("Voice assistant enabled")
            
    def show_food_recommendations(self):
        try:
            if self.weight_input.text() and self.height_input.text():
                weight = float(self.weight_input.text())
                height = float(self.height_input.text()) / 100
                bmi = weight / (height * height)
                
                # Create and show the recommendations window
                self.food_window = IndianFoodRecommendations(bmi)
                self.food_window.show()
            else:
                QMessageBox.warning(self, "Input Required", 
                                  "Please enter your weight and height first.")
        except ValueError:
            QMessageBox.warning(self, "Invalid Input", 
                              "Please enter valid weight and height values.")

    def update_calories_burned(self):
        """Calculate and update calories burned based on current session data"""
        try:
            # Get current values
            heart_rate = esp_data.get("heart_rate", 0)
            body_temp = max(esp_data.get("body_temp_pre", 37.0), esp_data.get("body_temp_post", 37.0))
            strength_count = esp_data.get("steps", 0)
            
            # Only calculate if we have valid heart rate data and user input
            if heart_rate > 40 and self.weight_input.text():
                # Get user data
                weight = float(self.weight_input.text())
                height = float(self.height_input.text()) if self.height_input.text() else 170
                
                age = 19
                gender_factor = 1
                
                if "age" in self.user_profile and self.user_profile["age"]:
                    try:
                        age = int(self.user_profile["age"])
                    except:
                        pass
                if "gender" in self.user_profile and self.user_profile["gender"]:
                    if self.user_profile["gender"] == "Female":
                        gender_factor = 0  
 
                # Calculate BMI
                height_m = height / 100  # Convert cm to m
                bmi = weight / (height_m * height_m)
                
                # Initialize time tracking if not already done
                if not hasattr(self, 'last_calorie_update'):
                    self.last_calorie_update = time.time()
                    self.total_calories = 0
                
                current_time = time.time()
                minutes_elapsed = (current_time - self.last_calorie_update) / 60
                hours_elapsed = minutes_elapsed / 60
                
                # Use Keytel equation for heart-rate based calculation
                calories_hr = minutes_elapsed * ((0.2017 * age + 0.1988 * weight + 0.6309 * heart_rate - 55.0969) * gender_factor + 
                                               (0.074 * age + 0.1263 * weight + 0.4472 * heart_rate - 20.4022) * (1 - gender_factor)) / 4.184
                
                # IMPROVED: Dynamic MET value based on pose intensity and heart rate
                yoga_intensity = "moderate"  # Default
                if hasattr(self, 'current_pose_name') and self.current_pose_name:
                    # Determine intensity based on pose name
                    intense_poses = ["crow", "headstand", "handstand", "wheel", "side plank"]
                    light_poses = ["child", "corpse", "mountain", "easy", "seated"]
                    
                    if any(pose in self.current_pose_name.lower() for pose in intense_poses):
                        yoga_intensity = "intense"
                    elif any(pose in self.current_pose_name.lower() for pose in light_poses):
                        yoga_intensity = "light"
                
                # Adjust intensity based on heart rate
                if heart_rate > 120:
                    yoga_intensity = "intense"
                elif heart_rate < 80 and yoga_intensity != "light":
                    yoga_intensity = "moderate"
                    
                # Set MET value based on intensity
                met_values = {"light": 2.5, "moderate": 4.0, "intense": 6.0}
                yoga_met = met_values.get(yoga_intensity, 4.0)
                
                # IMPROVED: More accurate temperature adjustment
                # Each degree above normal increases metabolism by ~13%
                temp_adjustment = 1.0 + max(0, (body_temp - 37.0) * 0.13)
                
                # IMPROVED: More accurate BMI adjustment
                if bmi < 18.5:
                    bmi_adjustment = 0.95  # Underweight
                elif bmi < 25:
                    bmi_adjustment = 1.0   # Normal weight
                elif bmi < 30:
                    bmi_adjustment = 1.05  # Overweight
                else:
                    bmi_adjustment = 1.1   # Obese
                    
                # Calculate MET-based calories
                calories_met = yoga_met * weight * hours_elapsed * temp_adjustment * bmi_adjustment
                
                # Average both methods for better accuracy
                calories = (calories_hr + calories_met) / 2
                
                # Add to total
                self.total_calories += calories
                
                # Update the calories display
                self.calories_card.update_value(f"{int(self.total_calories)}")
                
                # Update last update time
                self.last_calorie_update = current_time
                
        except Exception as e:
            print(f"Error calculating calories: {e}")

    def show_profile(self):
        """Show the user profile dialog"""
        self.profile_dialog = UserProfileDialog(self, self.user_profile)
        self.profile_dialog.profile_updated.connect(self.on_profile_updated)
        # Make the dialog modal to prevent interaction with main window
        self.profile_dialog.setWindowModality(Qt.WindowModality.ApplicationModal)
        self.profile_dialog.show()
        
    def on_profile_updated(self, profile_data):
        """Handle updated profile data"""
        self.user_profile = profile_data
        
        # Update weight and height inputs if they exist
        if "weight" in profile_data and profile_data["weight"]:
            self.weight_input.setText(profile_data["weight"])
        
        if "height" in profile_data and profile_data["height"]:
            self.height_input.setText(profile_data["height"])
            
        # Calculate BMI if both weight and height are available
        self.calculate_bmi()
        
    def load_user_profile(self):
        """Load user profile from file if it exists"""
        try:
            if os.path.exists("user_data/profile.json"):
                with open("user_data/profile.json", "r") as f:
                    self.user_profile = json.load(f)
                    
                # Update weight and height inputs if they exist
                if "weight" in self.user_profile and self.user_profile["weight"]:
                    self.weight_input.setText(self.user_profile["weight"])
                
                if "height" in self.user_profile and self.user_profile["height"]:
                    self.height_input.setText(self.user_profile["height"])
        except Exception as e:
            print(f"Error loading user profile: {e}")
            
    def calculate_bmi(self):
        """Calculate BMI based on weight and height"""
        try:
            if self.weight_input.text() and self.height_input.text():
                weight = float(self.weight_input.text())
                height = float(self.height_input.text()) / 100  # Convert cm to m
                
                if weight > 0 and height > 0:
                    bmi = weight / (height * height)
                    self.bmi_card.update_value(f"{bmi:.1f}")
                    
                    # Update BMI category
                    if bmi < 18.5:
                        self.bmi_card.update_category("Underweight", "#FF9800")  # Orange
                    elif bmi < 25:
                        self.bmi_card.update_category("Normal", "#4CAF50")  # Green
                    elif bmi < 30:
                        self.bmi_card.update_category("Overweight", "#FF5722")  # Deep Orange
                    else:
                        self.bmi_card.update_category("Obese", "#F44336")  # Red
                        
                    # Store BMI for food recommendations
                    self.bmi = bmi
        except Exception as e:
            print(f"Error calculating BMI: {e}")
# ---------------------------
# Main Application
# ---------------------------
if __name__ == "__main__":
    app = QtWidgets.QApplication(sys.argv)
    
    # Set application style
    app.setStyle("Fusion")
    
    # Set palette for a more modern look
    palette = QPalette()
    palette.setColor(QPalette.ColorRole.Window, QColor(249, 249, 249))
    palette.setColor(QPalette.ColorRole.WindowText, QColor(32, 33, 36))
    # ... rest of palette settings ...
    app.setPalette(palette)
    
    # Make sure the logo file exists before showing splash screen
    logo_path = "c:/Users/sriva/OneDrive/Desktop/YogKalp/YogKalp_logo.jpg"
    if not os.path.exists(logo_path):
        # If logo doesn't exist, show main app directly
        print("Logo file not found. Starting application without splash screen.")
        main_app = ModernYogaApp()
        main_app.show()
    else:
        # Show splash screen
        splash = SplashScreen()
        splash.show()
    
    sys.exit(app.exec())
